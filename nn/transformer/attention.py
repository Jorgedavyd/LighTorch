from torch import nn

"""
Types:
- GroupedQueryAttention
- MultiQueryAttention
- DefaultMultiHeadAttention
- SingleHeadAttention

You can use it with:
- SelfAttention
- CrossAttention

"""

class _Base(nn.Module):
    def 

__all__ = []